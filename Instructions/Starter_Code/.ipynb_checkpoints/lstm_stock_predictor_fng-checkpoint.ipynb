{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Fear and Greed Index\n",
    "\n",
    "In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin fear and greed index values to predict the 11th day closing price. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Prepare the data for training and testing\n",
    "2. Build and train a custom LSTM RNN\n",
    "3. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.\n",
    "\n",
    "You will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the X and y values\n",
    "4. Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.random' has no attribute 'set_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f074e5f5565f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\util\\deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_dw_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accessing local variables before they are created.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[0;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.random' has no attribute 'set_seed'"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)\n",
    "\n",
    "\n",
    "# Despite kicking errors, Tensorflow has always worked.  I've just ignored the warnings and errors.  \n",
    "# It works =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value\n",
       "date                  \n",
       "2019-07-29          19\n",
       "2019-07-28          16\n",
       "2019-07-27          47\n",
       "2019-07-26          24\n",
       "2019-07-25          42"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fear and greed sentiment data for Bitcoin\n",
    "df = pd.read_csv('btc_sentiment.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=\"fng_classification\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2019-07-25    9882.429688\n",
       "2019-07-26    9847.450195\n",
       "2019-07-27    9478.320313\n",
       "2019-07-28    9531.769531\n",
       "2019-07-29    9529.889648\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the historical closing prices for Bitcoin\n",
    "df2 = pd.read_csv('btc_historic.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)['Close']\n",
    "df2 = df2.sort_index()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "      <td>9882.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "      <td>9847.450195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "      <td>9478.320313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "      <td>9531.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "      <td>9529.889648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2019-07-25          42  9882.429688\n",
       "2019-07-26          24  9847.450195\n",
       "2019-07-27          47  9478.320313\n",
       "2019-07-28          16  9531.769531\n",
       "2019-07-29          19  9529.889648"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the data into a single DataFrame\n",
    "df = df.join(df2, how=\"inner\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>30</td>\n",
       "      <td>9114.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>15</td>\n",
       "      <td>8870.820313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-03</th>\n",
       "      <td>40</td>\n",
       "      <td>9251.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04</th>\n",
       "      <td>24</td>\n",
       "      <td>8218.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>11</td>\n",
       "      <td>6937.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2018-02-01          30  9114.719727\n",
       "2018-02-02          15  8870.820313\n",
       "2018-02-03          40  9251.269531\n",
       "2018-02-04          24  8218.049805\n",
       "2018-02-05          11  6937.080078"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous fng values\n",
    "# Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 3\n",
    "\n",
    "# Column index 0 is the 'fng_value' column\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 0\n",
    "target_column = 1\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "\n",
    "\n",
    "split = int(.7 * len(X))\n",
    "\n",
    "X_train = X[:split -1]  # includes everything from index 0 to the split @ 70% of data\n",
    "X_test = X[split:]   # includes everything after the 70% split (colon: after 'split')\n",
    "\n",
    "y_train = y[:split-1]  # same as X\n",
    "y_test = y[split:]   # same as X \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the features data X\n",
    "scaler.fit(X)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the target data Y\n",
    "scaler.fit(y)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[0.25287356]\n",
      "  [0.08045977]\n",
      "  [0.36781609]]\n",
      "\n",
      " [[0.08045977]\n",
      "  [0.36781609]\n",
      "  [0.18390805]]\n",
      "\n",
      " [[0.36781609]\n",
      "  [0.18390805]\n",
      "  [0.03448276]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.40229885]\n",
      "  [0.40229885]\n",
      "  [0.37931034]]\n",
      "\n",
      " [[0.40229885]\n",
      "  [0.37931034]\n",
      "  [0.34482759]]\n",
      "\n",
      " [[0.37931034]\n",
      "  [0.34482759]\n",
      "  [0.63218391]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Print some sample data after reshaping the datasets\n",
    "print (f\"X_train sample values:\\n{X_train[:3]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, you will design a custom LSTM RNN and fit (train) it using the training data.\n",
    "\n",
    "You will need to:\n",
    "1. Define the model architecture\n",
    "2. Compile the model\n",
    "3. Fit the model to the training data\n",
    "\n",
    "### Hints:\n",
    "You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# Note: The dropouts help prevent overfitting\n",
    "# Note: The input shape is the number of time steps and the number of indicators\n",
    "# Note: Batching inputs has a different input shape of Samples/TimeSteps/Features\n",
    "\n",
    "model = Sequential()  # instantiate the model \n",
    "\n",
    "\n",
    "number_units = 180   # Same as sample size\n",
    "dropout_fraction = 0.2  # Seemingly a good starting point.  Aggressive enough to keep data from stagnation, but also keeping 80% of the 'good' data\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units,\n",
    "         return_sequences=False))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 3, 180)            131040    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 3, 180)            0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 3, 180)            259920    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3, 180)            0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 180)               259920    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 181       \n",
      "=================================================================\n",
      "Total params: 651,061\n",
      "Trainable params: 651,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "376/376 [==============================] - 4s 10ms/sample - loss: 0.0771\n",
      "Epoch 2/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0576\n",
      "Epoch 3/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0713\n",
      "Epoch 4/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0734\n",
      "Epoch 5/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0650\n",
      "Epoch 6/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0595\n",
      "Epoch 7/50\n",
      "376/376 [==============================] - 1s 3ms/sample - loss: 0.0579\n",
      "Epoch 8/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0554 0s - l\n",
      "Epoch 9/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0544\n",
      "Epoch 10/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0520\n",
      "Epoch 11/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0522\n",
      "Epoch 12/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0494\n",
      "Epoch 13/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0489\n",
      "Epoch 14/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0479\n",
      "Epoch 15/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0472\n",
      "Epoch 16/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0461\n",
      "Epoch 17/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0457\n",
      "Epoch 18/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0450\n",
      "Epoch 19/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0443\n",
      "Epoch 20/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0450\n",
      "Epoch 21/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0445\n",
      "Epoch 22/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0440\n",
      "Epoch 23/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0438\n",
      "Epoch 24/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0436\n",
      "Epoch 25/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0419\n",
      "Epoch 26/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0421\n",
      "Epoch 27/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0420\n",
      "Epoch 28/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0421\n",
      "Epoch 29/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0418\n",
      "Epoch 30/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0408\n",
      "Epoch 31/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0416\n",
      "Epoch 32/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0405\n",
      "Epoch 33/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0405\n",
      "Epoch 34/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0401\n",
      "Epoch 35/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0398\n",
      "Epoch 36/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0396\n",
      "Epoch 37/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0400\n",
      "Epoch 38/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0397\n",
      "Epoch 39/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0386\n",
      "Epoch 40/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0386\n",
      "Epoch 41/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0393\n",
      "Epoch 42/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0390\n",
      "Epoch 43/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0383\n",
      "Epoch 44/50\n",
      "376/376 [==============================] - 1s 3ms/sample - loss: 0.0385\n",
      "Epoch 45/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0385\n",
      "Epoch 46/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0390\n",
      "Epoch 47/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0382\n",
      "Epoch 48/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0380\n",
      "Epoch 49/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0379\n",
      "Epoch 50/50\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.0382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d7a53f3bc8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "model.fit(X_train, y_train, epochs=epochs, shuffle=False, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Shuffle is set to \"FALSE\" because of the sequential nature of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 5ms/sample - loss: 0.0827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0827498737676644"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "\n",
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-18</th>\n",
       "      <td>3670.919922</td>\n",
       "      <td>6823.062012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-19</th>\n",
       "      <td>3912.570068</td>\n",
       "      <td>6721.378418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>3924.239990</td>\n",
       "      <td>7122.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-21</th>\n",
       "      <td>3974.050049</td>\n",
       "      <td>7641.061035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>3937.040039</td>\n",
       "      <td>8606.519531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Real    Predicted\n",
       "2019-02-18  3670.919922  6823.062012\n",
       "2019-02-19  3912.570068  6721.378418\n",
       "2019-02-20  3924.239990  7122.910156\n",
       "2019-02-21  3974.050049  7641.061035\n",
       "2019-02-22  3937.040039  8606.519531"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices): ]) \n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='3467'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"d8c6e2de-2122-4bcc-a098-d2b410fb024e\" data-root-id=\"3467\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"ec775090-2ea9-4904-8793-f18fa519437f\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"3503\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{\"callback\":null,\"formatters\":{\"@{index}\":\"datetime\"},\"renderers\":[{\"id\":\"3513\"},{\"id\":\"3543\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Variable\",\"@{Variable}\"],[\"index\",\"@{index}{%F %T}\"],[\"value\",\"@{value}\"]]},\"id\":\"3471\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"3508\",\"type\":\"Selection\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"3523\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"3525\",\"type\":\"DaysTicker\"},{\"attributes\":{\"label\":{\"value\":\"Real\"},\"renderers\":[{\"id\":\"3513\"}]},\"id\":\"3536\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"3490\",\"type\":\"SaveTool\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"3524\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"data\":{\"Variable\":[\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\"],\"index\":{\"__ndarray__\":\"AADAb96PdkIAAIDVMJB2QgAAQDuDkHZCAAAAodWQdkIAAMAGKJF2QgAAgGx6kXZCAABA0syRdkIAAAA4H5J2QgAAwJ1xknZCAACAA8SSdkIAAEBpFpN2QgAAAM9ok3ZCAADANLuTdkIAAICaDZR2QgAAQABglHZCAAAAZrKUdkIAAMDLBJV2QgAAgDFXlXZCAABAl6mVdkIAAAD9+5V2QgAAwGJOlnZCAACAyKCWdkIAAEAu85Z2QgAAAJRFl3ZCAADA+ZeXdkIAAIBf6pd2QgAAQMU8mHZCAAAAK4+YdkIAAMCQ4Zh2QgAAgPYzmXZCAABAXIaZdkIAAADC2Jl2QgAAwCcrmnZCAACAjX2adkIAAEDzz5p2QgAAAFkim3ZCAADAvnSbdkIAAIAkx5t2QgAAQIoZnHZCAAAA8GucdkIAAMBVvpx2QgAAgLsQnXZCAABAIWOddkIAAACHtZ12QgAAwOwHnnZCAACAUlqedkIAAEC4rJ52QgAAAB7/nnZCAADAg1GfdkIAAIDpo592QgAAQE/2n3ZCAAAAtUigdkIAAMAam6B2QgAAgIDtoHZCAABA5j+hdkIAAABMkqF2QgAAwLHkoXZCAACAFzeidkIAAEB9iaJ2QgAAAOPbonZCAADASC6jdkIAAICugKN2QgAAQBTTo3ZCAAAAeiWkdkIAAMDfd6R2QgAAgEXKpHZCAABAqxyldkIAAAARb6V2QgAAwHbBpXZCAACA3BOmdkIAAEBCZqZ2QgAAAKi4pnZCAADADQundkIAAIBzXad2QgAAQNmvp3ZCAAAAPwKodkIAAMCkVKh2QgAAgAqnqHZCAABAcPmodkIAAADWS6l2QgAAwDueqXZCAACAofCpdkIAAEAHQ6p2QgAAAG2VqnZCAADA0ueqdkIAAIA4Oqt2QgAAQJ6Mq3ZCAAAABN+rdkIAAMBpMax2QgAAgM+DrHZCAABANdasdkIAAACbKK12QgAAwAB7rXZCAACAZs2tdkIAAEDMH652QgAAADJyrnZCAADAl8SudkIAAID9Fq92QgAAQGNpr3ZCAAAAybuvdkIAAMAuDrB2QgAAgJRgsHZCAABA+rKwdkIAAABgBbF2QgAAwMVXsXZCAACAK6qxdkIAAECR/LF2QgAAAPdOsnZCAADAXKGydkIAAIDC87J2QgAAQChGs3ZCAAAAjpizdkIAAMDz6rN2QgAAgFk9tHZCAABAv4+0dkIAAAAl4rR2QgAAwIo0tXZCAACA8Ia1dkIAAEBW2bV2QgAAALwrtnZCAADAIX62dkIAAICH0LZ2QgAAQO0it3ZCAAAAU3W3dkIAAMC4x7d2QgAAgB4auHZCAABAhGy4dkIAAADqvrh2QgAAwE8RuXZCAACAtWO5dkIAAEAbtrl2QgAAAIEIunZCAADA5lq6dkIAAIBMrbp2QgAAQLL/unZCAAAAGFK7dkIAAMB9pLt2QgAAgOP2u3ZCAABASUm8dkIAAACvm7x2QgAAwBTuvHZCAACAekC9dkIAAEDgkr12QgAAAEblvXZCAADAqze+dkIAAIARir52QgAAQHfcvnZCAAAA3S6/dkIAAMBCgb92QgAAgKjTv3ZCAABADibAdkIAAAB0eMB2QgAAwNnKwHZCAACAPx3BdkIAAEClb8F2QgAAAAvCwXZCAADAcBTCdkIAAIDWZsJ2QgAAQDy5wnZCAAAAogvDdkIAAMAHXsN2QgAAgG2ww3ZC\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[162]},\"value\":{\"__ndarray__\":\"fzjVRQcL0kVIl95FfcjuRRR6Bkb1HQVGc5gBRh5DA0b41gdGYdADRqtT9kWz4dVFcs3ORZLMz0W56NBFSvnURWy70EUgHc5Foh3LRWHj1kXuDuZFlSv2RWVt9EW0ePZFm1X3RRMn90WVK/ZFZW30ReX59EVAG/dFjcD3RcBW+0Vn5/dFiUj8RcCb/EWyTfxFAafqRRR14EVxetlFxSvaRdoq20ULU+BFZKTrRY/F8UVbgf5FBoAARnnpB0Z/2QdGa4UKRpGBBEb/VgdGIwgMRqq/DEYhmAhGtQsIRviA/kWW6/xFvnvoRV9a/0UBFvFFQn38RQUc+0U1UAVGE3UGRg/DBEYnGgVGc0IHRl+qCEZazQlGwIb7RXJ/5EVGFdJFDRPTRVRy0kWSMtpFr53fRahn8kUpVv5FnesJRsPiCEbSXwlGvIUFRjGfDUZfwAxG95sTRuu5FkbhdBpGCOkaRvNtHEbIkBtG8koXRpE5EkaD6gxGNMIQRoiDEkYvyxJG4jkORqq/DEZ/LAtGlAcMRk/OD0Y2ERBGcqUSRmgDFEZx2RBGfCANRmAjBUahcAdGNHUARgQ/5EXfGMdF5uG7RX1S0UWyKeBFYsb+RXGn+0VhEfNF5TYERshiBkZsRg1GgzcVRj8kHUatgSBGc9AhRmYAIUb66yBGg/IgRlUqIkZWPCFG7yAiRlwpI0ZYJCVGzM8jRuGcHkYKuhBGgnYWRmYQE0aOTg5G/uESRnacGUb+eRVGiJIPRpdRE0azEhZGJZAdRh6xHUbKvApGcpDzRcnS50XGBetF5VHRRU7HsUVIMcFFFzvBRV9nzUUwkc9F6jjNRbYB00XZgMVFa9PGRf0huUWSMM1F\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[162]}},\"selected\":{\"id\":\"3538\"},\"selection_policy\":{\"id\":\"3552\"}},\"id\":\"3537\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"3491\",\"type\":\"PanTool\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"3495\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"label\":{\"value\":\"Predicted\"},\"renderers\":[{\"id\":\"3543\"}]},\"id\":\"3567\",\"type\":\"LegendItem\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"3526\",\"type\":\"DaysTicker\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer04230\",\"sizing_mode\":\"stretch_width\"},\"id\":\"3766\",\"type\":\"Spacer\"},{\"attributes\":{\"source\":{\"id\":\"3537\"}},\"id\":\"3544\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"3480\",\"type\":\"LinearScale\"},{\"attributes\":{\"data_source\":{\"id\":\"3537\"},\"glyph\":{\"id\":\"3540\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"3542\"},\"nonselection_glyph\":{\"id\":\"3541\"},\"selection_glyph\":null,\"view\":{\"id\":\"3544\"}},\"id\":\"3543\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"3511\",\"type\":\"Line\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"3529\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"text\":\"\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12pt\"}},\"id\":\"3474\",\"type\":\"Title\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"3471\"},{\"id\":\"3490\"},{\"id\":\"3491\"},{\"id\":\"3492\"},{\"id\":\"3493\"},{\"id\":\"3494\"}]},\"id\":\"3496\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"3505\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"3527\",\"type\":\"DaysTicker\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"3528\",\"type\":\"DaysTicker\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"3510\",\"type\":\"Line\"},{\"attributes\":{\"end\":1564358400000.0,\"reset_end\":1564358400000.0,\"reset_start\":1550448000000.0,\"start\":1550448000000.0,\"tags\":[[[\"index\",\"index\",null]]]},\"id\":\"3469\",\"type\":\"Range1d\"},{\"attributes\":{\"data_source\":{\"id\":\"3507\"},\"glyph\":{\"id\":\"3510\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"3512\"},\"nonselection_glyph\":{\"id\":\"3511\"},\"selection_glyph\":null,\"view\":{\"id\":\"3514\"}},\"id\":\"3513\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis_label\":\"Date\",\"bounds\":\"auto\",\"formatter\":{\"id\":\"3503\"},\"major_label_orientation\":\"horizontal\",\"ticker\":{\"id\":\"3483\"}},\"id\":\"3482\",\"type\":\"DatetimeAxis\"},{\"attributes\":{},\"id\":\"3478\",\"type\":\"LinearScale\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"3541\",\"type\":\"Line\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"3530\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"below\":[{\"id\":\"3482\"}],\"center\":[{\"id\":\"3485\"},{\"id\":\"3489\"}],\"left\":[{\"id\":\"3486\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"plot_height\":300,\"plot_width\":700,\"renderers\":[{\"id\":\"3513\"},{\"id\":\"3543\"}],\"right\":[{\"id\":\"3535\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"3474\"},\"toolbar\":{\"id\":\"3496\"},\"x_range\":{\"id\":\"3469\"},\"x_scale\":{\"id\":\"3478\"},\"y_range\":{\"id\":\"3470\"},\"y_scale\":{\"id\":\"3480\"}},\"id\":\"3473\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"3512\",\"type\":\"Line\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"3522\"},{\"id\":\"3523\"},{\"id\":\"3524\"},{\"id\":\"3525\"},{\"id\":\"3526\"},{\"id\":\"3527\"},{\"id\":\"3528\"},{\"id\":\"3529\"},{\"id\":\"3530\"},{\"id\":\"3531\"},{\"id\":\"3532\"},{\"id\":\"3533\"}]},\"id\":\"3483\",\"type\":\"DatetimeTicker\"},{\"attributes\":{\"axis\":{\"id\":\"3486\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"3489\",\"type\":\"Grid\"},{\"attributes\":{\"axis\":{\"id\":\"3482\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"3485\",\"type\":\"Grid\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"3531\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"overlay\":{\"id\":\"3495\"}},\"id\":\"3493\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"3538\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"3487\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"3492\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"3552\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"3532\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"children\":[{\"id\":\"3468\"},{\"id\":\"3473\"},{\"id\":\"3766\"}],\"margin\":[0,0,0,0],\"name\":\"Row04225\",\"tags\":[\"embedded\"]},\"id\":\"3467\",\"type\":\"Row\"},{\"attributes\":{\"axis_label\":\"Price\",\"bounds\":\"auto\",\"formatter\":{\"id\":\"3505\"},\"major_label_orientation\":\"horizontal\",\"ticker\":{\"id\":\"3487\"}},\"id\":\"3486\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"3507\"}},\"id\":\"3514\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"3520\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data\":{\"Variable\":[\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\"],\"index\":{\"__ndarray__\":\"AADAb96PdkIAAIDVMJB2QgAAQDuDkHZCAAAAodWQdkIAAMAGKJF2QgAAgGx6kXZCAABA0syRdkIAAAA4H5J2QgAAwJ1xknZCAACAA8SSdkIAAEBpFpN2QgAAAM9ok3ZCAADANLuTdkIAAICaDZR2QgAAQABglHZCAAAAZrKUdkIAAMDLBJV2QgAAgDFXlXZCAABAl6mVdkIAAAD9+5V2QgAAwGJOlnZCAACAyKCWdkIAAEAu85Z2QgAAAJRFl3ZCAADA+ZeXdkIAAIBf6pd2QgAAQMU8mHZCAAAAK4+YdkIAAMCQ4Zh2QgAAgPYzmXZCAABAXIaZdkIAAADC2Jl2QgAAwCcrmnZCAACAjX2adkIAAEDzz5p2QgAAAFkim3ZCAADAvnSbdkIAAIAkx5t2QgAAQIoZnHZCAAAA8GucdkIAAMBVvpx2QgAAgLsQnXZCAABAIWOddkIAAACHtZ12QgAAwOwHnnZCAACAUlqedkIAAEC4rJ52QgAAAB7/nnZCAADAg1GfdkIAAIDpo592QgAAQE/2n3ZCAAAAtUigdkIAAMAam6B2QgAAgIDtoHZCAABA5j+hdkIAAABMkqF2QgAAwLHkoXZCAACAFzeidkIAAEB9iaJ2QgAAAOPbonZCAADASC6jdkIAAICugKN2QgAAQBTTo3ZCAAAAeiWkdkIAAMDfd6R2QgAAgEXKpHZCAABAqxyldkIAAAARb6V2QgAAwHbBpXZCAACA3BOmdkIAAEBCZqZ2QgAAAKi4pnZCAADADQundkIAAIBzXad2QgAAQNmvp3ZCAAAAPwKodkIAAMCkVKh2QgAAgAqnqHZCAABAcPmodkIAAADWS6l2QgAAwDueqXZCAACAofCpdkIAAEAHQ6p2QgAAAG2VqnZCAADA0ueqdkIAAIA4Oqt2QgAAQJ6Mq3ZCAAAABN+rdkIAAMBpMax2QgAAgM+DrHZCAABANdasdkIAAACbKK12QgAAwAB7rXZCAACAZs2tdkIAAEDMH652QgAAADJyrnZCAADAl8SudkIAAID9Fq92QgAAQGNpr3ZCAAAAybuvdkIAAMAuDrB2QgAAgJRgsHZCAABA+rKwdkIAAABgBbF2QgAAwMVXsXZCAACAK6qxdkIAAECR/LF2QgAAAPdOsnZCAADAXKGydkIAAIDC87J2QgAAQChGs3ZCAAAAjpizdkIAAMDz6rN2QgAAgFk9tHZCAABAv4+0dkIAAAAl4rR2QgAAwIo0tXZCAACA8Ia1dkIAAEBW2bV2QgAAALwrtnZCAADAIX62dkIAAICH0LZ2QgAAQO0it3ZCAAAAU3W3dkIAAMC4x7d2QgAAgB4auHZCAABAhGy4dkIAAADqvrh2QgAAwE8RuXZCAACAtWO5dkIAAEAbtrl2QgAAAIEIunZCAADA5lq6dkIAAIBMrbp2QgAAQLL/unZCAAAAGFK7dkIAAMB9pLt2QgAAgOP2u3ZCAABASUm8dkIAAACvm7x2QgAAwBTuvHZCAACAekC9dkIAAEDgkr12QgAAAEblvXZCAADAqze+dkIAAIARir52QgAAQHfcvnZCAAAA3S6/dkIAAMBCgb92QgAAgKjTv3ZCAABADibAdkIAAAB0eMB2QgAAwNnKwHZCAACAPx3BdkIAAEClb8F2QgAAAAvCwXZCAADAcBTCdkIAAIDWZsJ2QgAAQDy5wnZCAAAAogvDdkIAAMAHXsN2QgAAgG2ww3ZC\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[162]},\"value\":{\"__ndarray__\":\"vjEEANetrED+8PPfI5GuQLwi+N96qK5AZsQFoBkMr0Ah5/1/FMKuQN0J9l8PH69AvjEEABc1sEBktfl/PXetQETdByAFC65AnEoGgMLTrUAj9gmgcO2tQGS1+X+93q1Ad0Xwv/XurUBWXvI/4QWuQKqhDcCeyK1A3Qn2X48mrUACDwwgXESuQHdF8L/1Ra5AH9jxXzhVrkCJug9ACjiuQLwi+N96165Ah6sDIK6zrkDhJw6gx0WuQP/w898jYa5AVV7yP+FMrkBWXvI/4VKuQELO+/8orq5ARN0HIAV2r0AAAAAAADyvQMqIC0CzKa9A4ScOoEdwr0AAAAAAgLGvQAIPDCDcOa9Ah6sDIK5Br0DfGAKAa06vQB/Y8V84NK9AZ8QFoBmprkAj9gmgcMyuQHdF8L/1m69Amzv6X+aIr0BOJQNAYQ+wQE4lA0AhFrBAKy/5n7AQsEB6VPzfUTewQIarAyDuKrNAvzEEAJdws0ALSPsfXDGzQLwi+N86t7NAAAAAAEDBs0BCzvv/KFG0QL4xBAAXrrRALT4FwExRtEBlxAWgmca0QNXQBmCPuLNA/////3/Zs0BCzvv/qNizQL4xBACXLbRAQ90HIEWts0DV0AZgz1y0QJxKBoBCdLRA/////7+ptEDpYP2fh6+0QIarAyAuzrRAZLX5f725tEDfGAKAqxK1QGXEBaAZo7VAIef9f5ROtUDgGAKAqyq0QL4xBAAXcrRAuyL433pttEDTwfo/c5i0QG8MAcD1dbRA9bcE4KPmtECR8/4/ig21QBefAmC4fLVATiUDQGF5tkAh5/1/FNC2QPa3BOAjorZA3xgCgCt0tkB6VPzfkbu2QG8MAcC1brdAbwwBwPUbuECR8/4/Sta4QApI+x9cF7xATiUDQKFBu0AKSPsfXH6+QE4lA0AhLL9AIOf9f9T3v0AKSPsfHMK+QG8MAcD1y7xAIef9fxRivEB6VPzfkQDAQJHz/j9KPr9Ah6sDIO4Lv0D2twTg48q9QAAAAACAxL5Amjv6X2Y8v0BOJQNAIXu/QN8YAoAdC8FAbwwBwJUowUCy2vy/bAfBQOlg/Z9H7MBA/////x8qwEBvDAHAVbPAQFlt/l/vtcBAIOf9f/QQwUBktfl/fbK/QBefAmB4/b1AkfP+P0pvvkAKSPsfXH++QE8lA0ChQr9A6WD9n8f9vkAsL/mfcNu9QAAAAAAAVb9AeVT831HtvkD1twTgI+6/QL4xBADJFcBAOIYA4Pr6wEDpYP2fx0rBQL4xBACXicFATiUDQAE8wkA4hgDg2rzBQMh5/x9FIMJAstr8v2ygwkBZbf5fb/XDQMh5/x/F4MRAstr8v/4zxUCy2vy/3o3FQN8YAoAr7sZAelT836M4yUDgGAKAC8nFQOlg/Z+HIchAs9r8vww2x0AXnwJghgjFQFht/l/vr8RAp5IBoBAuxUCGqwMgzmbHQCHn/X9CysVAAAAAAKB4xUAXnwJgePjFQHlU/N8jacZAIuf9fxQEyEAh5/1/govIQFlt/l+PocdAWW3+X48nxkBZbf5frwrHQIarAyD8McZAIef9fzTuw0BOJQNAITHFQBafAmC4Z8JATiUDQBPwwkCy2vy/LMfEQBefAmB4ksRAcAwBwLUDxUA4hgDgWq3EQFlt/l/vKsRATiUDQBM/w0B7VPzfERbDQL4xBAA3TcNA6WD9n7k7w0C+MQQAKYPCQCDn/X/incJA\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[162]}},\"selected\":{\"id\":\"3508\"},\"selection_policy\":{\"id\":\"3520\"}},\"id\":\"3507\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"3542\",\"type\":\"Line\"},{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"3540\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"3494\",\"type\":\"ResetTool\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer04229\",\"sizing_mode\":\"stretch_width\"},\"id\":\"3468\",\"type\":\"Spacer\"},{\"attributes\":{\"end\":13837.516308100001,\"reset_end\":13837.516308100001,\"reset_start\":2746.6838869000003,\"start\":2746.6838869000003,\"tags\":[[[\"value\",\"value\",null]]]},\"id\":\"3470\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"3533\",\"type\":\"YearsTicker\"},{\"attributes\":{\"click_policy\":\"mute\",\"items\":[{\"id\":\"3536\"},{\"id\":\"3567\"}],\"location\":[0,0],\"title\":\"Variable\"},\"id\":\"3535\",\"type\":\"Legend\"},{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"3522\",\"type\":\"AdaptiveTicker\"}],\"root_ids\":[\"3467\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "    var render_items = [{\"docid\":\"ec775090-2ea9-4904-8793-f18fa519437f\",\"root_ids\":[\"3467\"],\"roots\":{\"3467\":\"d8c6e2de-2122-4bcc-a098-d2b410fb024e\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":NdOverlay   [Variable]\n",
       "   :Curve   [index]   (value)"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "3467"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "stocks.hvplot.line(xlabel=\"Date\",\n",
    "                  ylabel=\"Price\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "### I have tried several different parameters for rolling windows randing from ***5 to 90 and 180 days***, as well a different unit numbers from ***5 to 10, through to 90 and 180*** units. Same result. \n",
    "\n",
    "#### The ***Delta*** between 'predicted' vs. 'actual' is always very far apart. \n",
    "\n",
    "If I use longer rolling windows or higher UNIT numbers, the delta between \"predicted\" vs. \"actual\" is in fact smaller; but not for a better result.  Quite the contrary, the predictibility of the 'predicted' curve effectively disappears because the over-fitting is so extreme that the FNG \"Predicted\" curve is effectively horizontal.  \n",
    "\n",
    "Second, and last, taken all of the foregoing together, what we can infer is that market sentiment or \"FNG\" is a poor predictor of price and trajectory. From March to May 2019, the consumer sentiment rails between highs and lows almost in a bi-polar or neurotic fashion.  During that same period, the actual Price stays pretty much flat and static.  \n",
    "\n",
    "Reviewing May to June, the consumer sentiment not only stays relatively stable, a huge dive of sentiment (near all-time-low) FNG during this 2 - month period, does not affect price whatsoever.  In fact, bitcoin Price ventures into a meotoric rise in spite of that negative sentiment to reach its all-time-high of $12,000; again, in spite of the negative FNG.  \n",
    "\n",
    "In closing, FNG, or consumer sentiment is truly a poor predictor for closing price having no relationship, and in some cases even an inverse relationship to asset performance.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
